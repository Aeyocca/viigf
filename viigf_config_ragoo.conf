#!/bin/bash
#configuration file for viigf pipeline
#06-26-18
#Alan Yocca
#01-15-19
#ragoo genomes

#Force;
FORCE="false"

#Working directory, all directories will be made realtive to that, have a few other files relative to this if you so choose
#*********NO TRAILING SLASH AT THE END OF THIS PATH"
WKDIR="/mnt/gs18/scratch/users/yoccaala/06_ragoo_assemblies"

#scratch directory, where everything you don't need will be thrown as soon as you no longer need it
#sorry not sorry its all just going there, not taking the time to organize it
#scratch is also accessible via the $SCRATCH variable according to the hpcc website, but I think this is a more explicit way to do it
#SCRATCH_DIR="/mnt/scratch/yoccaala/"
#*****Depreciated, just going with ${SCRATCH} environmental variable
#if there is somewhere else you want the cleaners to dump things, go change them, or ask me I will switch it for you

#read directory, location of the reads
READ_DIR="/mnt/gs18/scratch/users/yoccaala/06_ragoo_assemblies/04_trimmed"

#Error output if different from default ${WKDIR}/Error_files
EO_DIR=${WKDIR}/Error_files

#Script_dir
SCRIPT_DIR="/mnt/research/edgerpat_lab/AlanY/01_athal_cns/slurm"

#Reference genome, full path of the reference genome
REF_GENOME="/mnt/research/edgerpat_lab/AlanY/01_athal_cns/assembly_golicz16/05_reference/TAIR10_ref.fasta"

#estimated genome size
#whatever you want to put it at,
#Default is A thaliana
#only affects the estimated read coverage estimate given in output statstics file
EST_G_SIZE="135000000"

#raw read length
#for both read depth calculation and determination of requested walltime
RAW_READ_LENGTH="100"

#Set walltime for variant incorporation step, a few suggestions:
#~70x Arabidopsis thaliana read depth takes about 3 hours
#The majority involved mapping reads, and sorting the BAM file
#~200x read depth takes ~11 hours, ooo weee
#requesting 4 hours or less will SIGNIFICANTLY reduce the amount of time spent in the queue
#if you leave it blank, will default to 4:00:00 (4 hours)
#Also looks like PBJ takes slightly over 4 hours with ~200x read depth. I would bump to 6 hours if you have this
#I didn't include variables for increasing trimmomatic or fastqc over 4 hours, I don't think its necessary
#edit later: wanted to run a list of files that straddle this barrier, dont want long ones exceeding walltime, dont want short ones sitting in queue forever
#Switch to manually enter walltime, otherwise, will wc -l and approximate based on that and raw read length specified above
#if you have it set to no, and something exceeds walltime, check script for specified walltime, come back here, switch manual on, and give it more than it had
#keeping this at no may take a little longer while it calculates how many reads
#oooo could do file size as a proxy... yea.. still not sure if can do gzipped reads
#yea doing file size as a proxy of how long walltime to use
MANUAL_WALLTIME="Y"

if [[ ${MANUAL_WALLTIME} =~ ^[Yy] ]]; then
	#for trimmomatic step
	WALLTIME="04:00:00"
	VAR_INC_WALLTIME="04:00:00"
	PBJ_WALLTIME="04:00:00"
fi

#this loop allows us to jump off from the viigf_launch.sh script
#"if either of these variables are undefined"
if [[ -z ${VAR_INC_WALLTIME} ]] || [[ -z ${PBJ_WALLTIME} ]]; then
	#for trimmomatic step
        WALLTIME="04:00:00"
	VAR_INC_WALLTIME=${WALLTIME}
        PBJ_WALLTIME=${WALLTIME}
fi

#INFILE, this is something I commonly use in my pipeline processes for file naming
#it is also handy for array jobs
#every line of INFILE is a base filename, I use it here as the SRA id
#example line of test INFILE:
#[yoccaala@dev-intel14 qsub]$ head ../assembly_golicz16/ler_0_sra.txt 
#SRR3166543
#SRR3156160
#path could be full or relative to working directory
#highly recommend full path
#INFILE="/mnt/gs18/scratch/users/yoccaala/06_ragoo_assemblies/ragoo_list.txt"
INFILE="/mnt/gs18/scratch/users/yoccaala/06_ragoo_assemblies/ragoo_srr_list.txt"

#Isolate base file name for this iteration
LINE=`/bin/sed -n ${SLURM_ARRAY_TASK_ID}p ${INFILE}`

#output file
#specify the file to write output statistics for this run to
#path relative to working directory or full path, your choice
#highly recommend full path
#***********will throw previous output file to scratch if rerunning an assembly on the same base name (LINE)********************
#***********if starting after trimming step for the second time, will just add to the existing one, but header information will NOT be updated******************
OUTFILE="/mnt/research/edgerpat_lab/AlanY/01_athal_cns/assembly_golicz16/viigf_out_stat_${LINE}.txt"

#variant incorporation step starting point
##if starting from 1, the first genome reads will be mapped to is TAIR10
##if starting after 1 (ie failed at a later step, running more rounds after original run):
###********MAKE SURE THE LAST VARIANT INC GENOME STILL EXISTS**********
# due to data amount considerations, the last round genome (along with pretty much everything we don't need) will be thrown to scratch
VAR_START=1
#variant incorporation step final iteration
VAR_LAST=3

###********MAKE SURE THE LAST PBJ GENOME STILL EXISTS**********
PBJ_START=1
PBJ_FINISH=6

#cleaners
#should we run cleaners? I almost always recommend this, have the switch here because helped during development
RUN_CLEANERS="nope"
#CLEANER_VAR_INC="/mnt/research/edgerpat_lab/AlanY/01_athal_cns/qsub/viigf_cleaner_var_inc.sh"
#CLEANER_PBJ="/mnt/research/edgerpat_lab/AlanY/01_athal_cns/qsub/viigf_cleaner_pbj.sh"

#maybe some point later add a customizable var in sam / bam / final tag but I like how they are right now

#switch to not run full thing
#defaults to yes, to continue, just make sure starts with capital or lowercase y
CONTINUE="nope"
